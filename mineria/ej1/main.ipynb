{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica: Evaluación Minería de Data Streams\n",
    "\n",
    "- Asignatura: Datos temporales y complejos\n",
    "- Autor: Mira Abad, Alejandro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-15T15:54:00.425434800Z",
     "start_time": "2023-05-15T15:54:00.401378600Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns.fpgrowth import fpgrowth"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1\n",
    "\n",
    "Sea la siguiente secuencia de 50 valores:\n",
    "\n",
    "`abceebdabaeedbdbabdcecdeabdbacedddacbbeabbcdacbeab`\n",
    "\n",
    "Aplique el algoritmo de Lossy Counting para epsilón igual a 0,1 hasta b=5 inclusive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-15T15:54:01.184768300Z",
     "start_time": "2023-05-15T15:54:01.178765100Z"
    }
   },
   "outputs": [],
   "source": [
    "sec = [\"a\",\"b\",\"c\",\"e\",\"e\",\"b\",\"d\",\"a\",\"b\",\"a\",\"e\",\"e\",\"d\",\"b\",\"d\",\"b\",\"a\",\"b\",\"d\",\"c\",\"e\",\"c\",\"d\",\"e\",\"a\",\"b\",\"d\",\"b\",\"a\",\"c\",\"e\",\"d\",\"d\",\"d\",\"a\",\"c\",\"b\",\"b\",\"e\",\"a\",\"b\",\"b\",\"c\",\"d\",\"a\",\"c\",\"b\",\"e\",\"a\",\"b\"]\n",
    "\n",
    "epsiolon = 0.1\n",
    "max_b = 5\n",
    "w_intervalo = int(1/epsiolon)\n",
    "n = len(sec)\n",
    "b = int(n/w_intervalo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-15T15:54:08.502822300Z",
     "start_time": "2023-05-15T15:54:08.491272300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'b': [0, 0], 'e': [0, 0], 'c': [0, 0], 'd': [0, 0], 'a': [0, 0]}\n"
     ]
    }
   ],
   "source": [
    "# Convierte la lista a un conjunto para eliminar duplicados\n",
    "conjunto = set(sec)\n",
    "\n",
    "# Convierte el conjunto a un diccionario\n",
    "# Como los diccionarios necesitan pares clave-valor, vamos a usar los elementos de la lista como claves y todos los valores serán None\n",
    "freq_dict = {clave: [0, 0] for clave in conjunto}\n",
    "\n",
    "print(freq_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intervalo 1 - dic: \n",
      " {'b': [3, 0], 'e': [0, 1], 'c': [0, 1], 'd': [0, 1], 'a': [3, 0]} \n",
      "\n",
      "Intervalo 2 - dic: \n",
      " {'b': [6, 0], 'e': [0, 2], 'c': [0, 2], 'd': [3, 1], 'a': [4, 0]} \n",
      "\n",
      "Intervalo 3 - dic: \n",
      " {'b': [8, 0], 'e': [0, 3], 'c': [0, 3], 'd': [5, 1], 'a': [6, 0]} \n",
      "\n",
      "Intervalo 4 - dic: \n",
      " {'b': [10, 0], 'e': [0, 4], 'c': [0, 4], 'd': [8, 1], 'a': [8, 0]} \n",
      "\n",
      "Intervalo 5 - dic: \n",
      " {'b': [14, 0], 'e': [0, 5], 'c': [0, 5], 'd': [9, 1], 'a': [10, 0]} \n",
      "\n",
      "Frequent items:\n",
      "b - 0\n",
      "d - 1\n",
      "a - 0\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,max_b+1):\n",
    "    sub_sec = sec[(i-1)*10:i*10]\n",
    "    \n",
    "    for item in sub_sec:\n",
    "        freq_dict[item][0] += 1\n",
    "    \n",
    "    for key in conjunto:\n",
    "        check = freq_dict[key][0] + freq_dict[key][1]\n",
    "\n",
    "        if check <= i+1 and freq_dict[key][0] != 0:\n",
    "            freq_dict[key][0] = 0\n",
    "            freq_dict[key][1] += 1\n",
    "    \n",
    "    print(f\"Intervalo {i} - dic: \\n {freq_dict} \\n\")\n",
    "\n",
    "print(f\"Frequent items:\")\n",
    "\n",
    "for key in conjunto:\n",
    "    if freq_dict[key][0] != 0:\n",
    "        print(f\"{key} - {freq_dict[key][1]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2\n",
    "\n",
    "Dadas las siguientes 8 “compras” de productos\n",
    "\n",
    "CDAB\n",
    "BCA\n",
    "DA\n",
    "EBA\n",
    "CDA\n",
    "EBC\n",
    "ABDE\n",
    "BCE\n",
    "\n",
    "Construya mediante FP trees los conjuntos frecuentes con soporte mínimo 50% (esto es, de frecuencia 4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['A', 'B', 'C', 'D'], ['A', 'B', 'C'], ['A', 'D'], ['A', 'B', 'E'], ['A', 'C', 'D'], ['B', 'C', 'E'], ['A', 'B', 'D', 'E'], ['B', 'C', 'E']]\n"
     ]
    }
   ],
   "source": [
    "transactions = [[\"C\",\"D\",\"A\",\"B\"],[\"B\",\"C\",\"A\"],[\"D\",\"A\"],[\"E\",\"B\",\"A\"],[\"C\",\"D\",\"A\"],[\"E\",\"B\",\"C\"],[\"A\",\"B\",\"D\",\"E\"],[\"B\",\"C\",\"E\"]]\n",
    "\n",
    "# Cuenta la frecuencia de cada elemento\n",
    "counter = Counter(element for transaction in transactions for element in transaction)\n",
    "\n",
    "# Ordena cada transacción en función de la frecuencia de sus elementos\n",
    "sorted_transactions = [sorted(transaction, key=lambda x: (-counter[x], x)) for transaction in transactions]\n",
    "\n",
    "print(sorted_transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_freq_itemsets(transactions, min_support_abs=0):\n",
    "    # our min support is 7, but it has to be expressed as a percentage for mlxtend\n",
    "    min_support = min_support_abs/len(transactions) \n",
    "    # compute the frequent itemsets using fpgriowth from mlxtend\n",
    "    frequent_itemsets = fpgrowth(transactions, min_support=min_support, use_colnames = True)\n",
    "    # all unique support count\n",
    "    su = frequent_itemsets.support.unique() \n",
    "\n",
    "    return frequent_itemsets, su\n",
    "\n",
    "def convert_list_to_one_hot(list_df):\n",
    "    # instantiate a transaction encoder\n",
    "    transactionencoder = TransactionEncoder()\n",
    "    # fit the transaction encoder using the list of transaction tuples\n",
    "    transactionencoder.fit(list_df)\n",
    "    # transform the list of transaction tuples into an array of encoded transactions\n",
    "    encoded_transactions = transactionencoder.transform(list_df)\n",
    "    # convert the array of encoded transactions into a dataframe\n",
    "    encoded_transactions_df = pd.DataFrame(encoded_transactions, columns=transactionencoder.columns_)\n",
    "\n",
    "    return encoded_transactions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent itmesets: \n",
      "------------------------- \n",
      "    support itemsets\n",
      "0    0.750      (B)\n",
      "1    0.750      (A)\n",
      "2    0.625      (C)\n",
      "3    0.500      (D)\n",
      "4    0.500      (E)\n",
      "5    0.500   (A, B)\n",
      "6    0.500   (C, B)\n",
      "7    0.500   (D, A)\n",
      "8    0.500   (E, B) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoded_transactions = convert_list_to_one_hot(transactions) # Convert to one hot encoding\n",
    "freq_itemsets, su = get_freq_itemsets(encoded_transactions, 4) # Get frequent itemsets\n",
    "\n",
    "print(f\"Frequent itmesets: \\n------------------------- \\n {freq_itemsets} \\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "U1-Nyznf3vH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
